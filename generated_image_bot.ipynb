{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from adain_nst_model import Model, VGGEncoder, Decoder, RC\n",
    "import sys\n",
    "\n",
    "from aiogram import Bot, Dispatcher\n",
    "from aiogram.types import FSInputFile\n",
    "from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton\n",
    "from aiogram.utils.keyboard import InlineKeyboardBuilder\n",
    "from aiogram.types import Message\n",
    "from aiogram.filters import Command\n",
    "from aiogram.fsm.context import FSMContext\n",
    "from aiogram.fsm.storage.memory import MemoryStorage\n",
    "from aiogram.fsm.state import StatesGroup, State\n",
    "from aiogram import F\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "import nest_asyncio\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка изображений\n",
    "def load_image(image_path, target_size=None):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(target_size) if target_size else transforms.Lambda(lambda x: x),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    std = torch.tensor([0.229, 0.224, 0.225])\n",
    "    tensor = tensor.squeeze(0)  # Убираем batch dimension\n",
    "    tensor = tensor * std[:, None, None] + mean[:, None, None]  # Обратная нормализация\n",
    "    tensor = torch.clamp(tensor, 0, 1)  # Обрезаем значения в диапазон [0, 1]\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qwe\\AppData\\Local\\Temp\\ipykernel_11416\\2665659868.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('model.pth', map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (vgg_encoder): VGGEncoder(\n",
       "    (slice1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (slice2): Sequential(\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "    )\n",
       "    (slice3): Sequential(\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "    )\n",
       "    (slice4): Sequential(\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (17): ReLU(inplace=True)\n",
       "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (rc1): RC(\n",
       "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (rc2): RC(\n",
       "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (rc3): RC(\n",
       "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (rc4): RC(\n",
       "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (rc5): RC(\n",
       "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (rc6): RC(\n",
       "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (rc7): RC(\n",
       "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (rc8): RC(\n",
       "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (rc9): RC(\n",
       "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (vgg_encode): VGGEncoder(\n",
       "    (slice1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (slice2): Sequential(\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "    )\n",
       "    (slice3): Sequential(\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "    )\n",
       "    (slice4): Sequential(\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (17): ReLU(inplace=True)\n",
       "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model = torch.load('model.pth', map_location=torch.device(\"cpu\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бот запущен!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "TOKEN = \"Ваш токен\"\n",
    "\n",
    "SAVE_DIR = \"temp_images\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Инициализация бота и диспетчера\n",
    "bot = Bot(token=TOKEN)\n",
    "storage = MemoryStorage()\n",
    "dp = Dispatcher(storage=storage)\n",
    "\n",
    "# Определение состояний\n",
    "class ImageProcessingState(StatesGroup):\n",
    "    waiting_for_first_image = State()\n",
    "    waiting_for_second_image = State()\n",
    "\n",
    "# Команда /start\n",
    "@dp.message(Command(\"start\"))\n",
    "async def start_command(message: Message, state: FSMContext):\n",
    "    await state.set_state(ImageProcessingState.waiting_for_first_image)\n",
    "    await message.answer(\"Привет! Отправьте первое изображение (Контентное).\")\n",
    "\n",
    "# Прием первого изображения\n",
    "@dp.message(ImageProcessingState.waiting_for_first_image, F.photo | F.document)\n",
    "async def first_image(message: Message, state: FSMContext):\n",
    "    if message.photo:\n",
    "        # Получаем фото с наивысшим качеством\n",
    "        photo = message.photo[-1]\n",
    "        file_id = photo.file_id\n",
    "        \n",
    "        file = await bot.get_file(file_id)\n",
    "        first_image_path = f\"{SAVE_DIR}/{file.file_id}\"\n",
    "        \n",
    "        # Загружаем файл по полученному пути\n",
    "        await bot.download_file(file.file_path, first_image_path)\n",
    "    elif message.document and message.document.mime_type.startswith(\"image/\"):\n",
    "        # Если это изображение как документ\n",
    "        document = message.document\n",
    "        file_id = document.file_id\n",
    "        \n",
    "        # Получаем файл через bot.get_file\n",
    "        file = await bot.get_file(file_id)\n",
    "        first_image_path = f\"{SAVE_DIR}/{file.file_id}\"\n",
    "        \n",
    "        # Загружаем файл по полученному пути\n",
    "        await bot.download_file(file.file_path, first_image_path)\n",
    "    else:\n",
    "        await message.answer(\"Отправьте изображение в формате фото или файла.\")\n",
    "        return\n",
    "\n",
    "    # Сохраняем путь к первому изображению в состояние\n",
    "    await state.update_data(first_image_path=first_image_path)\n",
    "    await state.set_state(ImageProcessingState.waiting_for_second_image)\n",
    "    await message.answer(\"Первое изображение получено! Теперь отправьте второе изображение (Стилевое).\")\n",
    "\n",
    "\n",
    "# Прием второго изображения\n",
    "@dp.message(ImageProcessingState.waiting_for_second_image, F.photo | F.document)\n",
    "async def second_image(message: Message, state: FSMContext):\n",
    "    if message.photo:\n",
    "\n",
    "        photo = message.photo[-1]\n",
    "        file_id = photo.file_id\n",
    "        \n",
    "        file = await bot.get_file(file_id)\n",
    "        second_image_path = f\"{SAVE_DIR}/{file.file_id}\"\n",
    "        \n",
    "        # Загружаем файл по полученному пути\n",
    "        await bot.download_file(file.file_path, second_image_path)\n",
    "    elif message.document and message.document.mime_type.startswith(\"image/\"):\n",
    "        # Если это изображение как документ\n",
    "        document = message.document\n",
    "        file_id = document.file_id\n",
    "        \n",
    "        file = await bot.get_file(file_id)\n",
    "        second_image_path = f\"{SAVE_DIR}/{file.file_id}\"\n",
    "        \n",
    "        # Загружаем файл по полученному пути\n",
    "        await bot.download_file(file.file_path, second_image_path)\n",
    "    else:\n",
    "        await message.answer(\"Отправьте изображение в формате фото или файла.\")\n",
    "        return\n",
    "\n",
    "    # Сохраняем путь ко второму изображению в состояние\n",
    "    await state.update_data(second_image_path=second_image_path)\n",
    "    await state.set_state(ImageProcessingState.waiting_for_second_image)\n",
    "    await message.answer(\"Второе изображение получено! Ожидайте результат.\")\n",
    "\n",
    "    # Получаем данные о первом изображении из состояния\n",
    "    data = await state.get_data()\n",
    "    first_image_path = data.get(\"first_image_path\")\n",
    "\n",
    "    # Обрабатываем изображения\n",
    "    generated_image_path = await process_images_with_model(first_image_path, second_image_path)\n",
    "\n",
    "    # Отправляем результат пользователю\n",
    "    with open(generated_image_path, \"rb\") as result_file:\n",
    "        input_file = FSInputFile(result_file.name)\n",
    "        await message.answer_photo(input_file, caption=\"Вот результат обработки!\")\n",
    "\n",
    "    # Удаляем временные файлы\n",
    "    delete_temp_files(first_image_path, second_image_path, generated_image_path)\n",
    "\n",
    "    # Завершаем состояние\n",
    "    await state.clear()\n",
    "\n",
    "    # Спрашиваем, продолжить ли обработку\n",
    "    await message.answer(\"Хотите продолжить обработку?\", reply_markup=get_continue_keyboard())\n",
    "\n",
    "\n",
    "# Клавиатура для вопроса \"Продолжить?\"\n",
    "def get_continue_keyboard():\n",
    "    builder = InlineKeyboardBuilder()\n",
    "    builder.add(\n",
    "        InlineKeyboardButton(text=\"Да\", callback_data=\"continue_yes\"),\n",
    "        InlineKeyboardButton(text=\"Нет\", callback_data=\"continue_no\")\n",
    "    )\n",
    "    return builder.as_markup()\n",
    "\n",
    "\n",
    "\n",
    "# Обработчик ответа \"Да\" или \"Нет\"\n",
    "@dp.callback_query(F.data == \"continue_yes\")\n",
    "async def continue_processing(callback_query, state: FSMContext):\n",
    "    await state.set_state(ImageProcessingState.waiting_for_first_image)\n",
    "    await callback_query.message.edit_text(\"Хорошо! Отправьте первое изображение.\")\n",
    "\n",
    "@dp.callback_query(F.data == \"continue_no\")\n",
    "async def stop_processing(callback_query, state: FSMContext):\n",
    "    # Сообщение с инструкцией\n",
    "    instructions = (\n",
    "        \"Спасибо за использование бота!\\n\"\n",
    "        \"Чтобы начать обработку заново, отправьте команду /start.\\n\\n\"\n",
    "        \"Инструкция:\\n\"\n",
    "        \"1. Отправьте два изображения по очереди.\\n\"\n",
    "        \"2. Получите результат обработки.\"\n",
    "    )\n",
    "    await callback_query.message.edit_text(instructions)\n",
    "\n",
    "    # Сброс состояния\n",
    "    await state.clear()    \n",
    "\n",
    "# Удаление временных файлов\n",
    "def delete_temp_files(*file_paths):\n",
    "    for file_path in file_paths:\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "\n",
    "# Функция обработки изображений через нейросеть\n",
    "async def process_images_with_model(image1_path, image2_path):\n",
    "    # Загружаем изображения\n",
    "    content_image = load_image(image1_path, target_size=(512, 512))\n",
    "    style_image = load_image(image2_path, target_size=(512, 512))\n",
    "\n",
    "    generate_image = model.generate(content_image, style_image)\n",
    "    generate_image = denormalize(generate_image).detach().cpu()\n",
    "\n",
    "    to_pil = transforms.ToPILImage()\n",
    "    result_image = to_pil(generate_image) \n",
    "\n",
    "    # Сохраняем результат\n",
    "    result_path = f\"{SAVE_DIR}/result_image.jpg\"\n",
    "    result_image.save(result_path)\n",
    "    return result_path\n",
    "\n",
    "\n",
    "# Основная функция запуска\n",
    "async def main():\n",
    "    print(\"Бот запущен!\")\n",
    "    await dp.start_polling(bot)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if sys.platform.startswith(\"win\") and hasattr(asyncio, \"WindowsSelectorEventLoopPolicy\"):\n",
    "        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())  \n",
    "\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
